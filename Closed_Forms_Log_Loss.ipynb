{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-mQl_AlTRH8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Log-Loss\n",
        "\n",
        "In this notebook, we will discuss a closed form solution for logistic regression when the observed labels/targets are in the open interval $(0,1)$. For a dataset $D_n = \\{(X_i,Y_i)\\}_{i=1}^n$ where $X_i\\in \\mathbb{R}^d$ and $Y_i \\in (0,1)$ for all $i \\in [n]$, the log-loss with sigmoid link function is defined as\n",
        "\n",
        "$$\n",
        "L(\\theta) = \\sum_{i=1}^n Y_i \\log \\frac{1}{\\sigma(X_i^\\top \\theta)} + (1-Y_i)\\log\\frac{1}{1-\\sigma(X_i^\\top \\theta)}\n",
        "$$\n",
        "where $\\theta \\in \\mathbb{R}^d$ and $\\sigma(x) = 1 / (1 + \\exp(-x))$ is the sigmoid activation function.\n",
        "\n",
        "The gradient of $L(\\theta)$ with respect to $\\theta$ is simply\n",
        "$$\n",
        "\\nabla_\\theta L(\\theta) = \\sum_{i=1}^n (\\sigma(X_i^\\top \\theta) - Y_i)X_i\\,.\n",
        "$$\n",
        "In order to minimize $L(\\theta)$, it sufficies to find a $\\bar\\theta$ such that $\\nabla_\\theta L(\\bar\\theta) = 0$. So long as $Y_i \\in (0,1)$ this can be achieved by noticing that for any $i \\in [n]$\n",
        "\n",
        "$$\n",
        "\\sigma(X_i^\\top \\theta) - Y_i = 0 \\implies \\sigma(X_i^\\top \\theta) = Y_i \\implies X_i^\\top \\theta = \\log \\frac{Y_i}{1-Y_i} \\implies X_i^\\top \\theta - \\log \\frac{Y_i}{1-Y_i} = 0 = \\sigma(X_i^\\top \\theta) - Y_i\\,.\n",
        "$$\n",
        "Therefore\n",
        "$$\n",
        "\\nabla_\\theta L(\\theta) = 0 \\approx \\sum_{i=1}^n \\left( X_i^\\top \\theta - \\underbrace{\\log \\frac{Y_i}{1-Y_i}}_{Z_i}\\right)X_i = \\sum_{i=1}^n \\left( X_i^\\top \\theta - Z_i\\right)X_i\\,.\n",
        "$$\n",
        "which gives us that $\\bar \\theta \\approx (X_i^\\top X_i)^{-1} X_i^\\top Z_i$. Note that we use $\\approx$ since we are note including information about the individual $X_i$'s when reweighting the targets.  \n",
        "\n",
        "Of course one can emperical verify whether this holds.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hHd52Tk8TUgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy as sc\n",
        "\n",
        "def sigmoid(x):\n",
        "    x[x < -36] = -36\n",
        "    x[x > 36] = 36\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "d = 10\n",
        "n = 100000\n",
        "trials = 1500000\n",
        "X = np.random.normal(size=(n,d))\n",
        "theta_star = np.random.uniform(low=0,high=3,size=d)\n",
        "Y = np.zeros(n)\n",
        "while 0 in Y or 1 in Y:\n",
        "  theta_star = np.random.uniform(low=0,high=1,size=d)\n",
        "  Y = np.random.binomial(trials, sigmoid(X@theta_star)) / trials\n"
      ],
      "metadata": {
        "id": "ynh6gub6WzcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid_Regression(object):\n",
        "    def __init__(self, features, obs, d, theta_init, minimizer):\n",
        "        self.features = features\n",
        "        self.obs = obs\n",
        "        self.n = len(obs)\n",
        "        self.d = d\n",
        "        self.theta_init = theta_init\n",
        "        self.minimizer = minimizer\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        x[x < -36] = -36\n",
        "        x[x > 36] = 36\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def objective_function(self, theta, X, Y):\n",
        "        p = self.sigmoid(X @ theta)\n",
        "        return -1.0 * np.sum(Y * np.log(p) + (1 - Y) * np.log(1 - p))\n",
        "\n",
        "    def objective_grad(self, theta, X, Y):\n",
        "        p = self.sigmoid(np.matmul(X,theta))\n",
        "        scalar = p - Y\n",
        "        return scalar.T @ X\n",
        "\n",
        "    def logistic_regression(self):\n",
        "        self.res = sc.optimize.minimize(\n",
        "            self.objective_function,\n",
        "            x0 = self.theta_init,\n",
        "            args=(self.features,self.obs),\n",
        "            jac = self.objective_grad,\n",
        "            method = self.minimizer,\n",
        "            options={\"gtol\":1e-8}\n",
        "        )\n",
        "        return self.res.x"
      ],
      "metadata": {
        "id": "ApgJjpOyXm1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = Sigmoid_Regression(X, Y, d, np.zeros(d), 'bfgs')\n",
        "theta1 = clf.logistic_regression()\n",
        "\n",
        "theta_closed_form = np.linalg.solve(X.T @ X, X.T @ np.log(Y / (1-Y)))"
      ],
      "metadata": {
        "id": "zjD-_WTfYLHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.linalg.norm(theta_star - theta_closed_form)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpI2jvowYVxG",
        "outputId": "ad3f6416-f43d-4cb5-f7dd-f78c496dc1f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0509288544447957e-05"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.linalg.norm(theta_star - theta1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWaemtZ2YgwM",
        "outputId": "c612ec1a-1807-4ffe-dc9b-772276a60ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.4848336634736298e-05"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theta1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMkzu79sZikn",
        "outputId": "52ac6e1f-e582-4a2b-bddf-997d4a481b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.35809734, 0.79947218, 0.92197344, 0.07150805, 0.204389  ,\n",
              "       0.63713671, 0.06229981, 0.72916141, 0.88325694, 0.30439809])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theta_closed_form"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcm18aYeZoMP",
        "outputId": "570f0366-227f-43be-fd03-2bd3e662e048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.35808919, 0.79948057, 0.92197332, 0.07151759, 0.20439192,\n",
              "       0.63713304, 0.06229445, 0.72915478, 0.88326779, 0.30440302])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QQGJO-L2ZpIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note things get a bit different if we look at the gradient of both the closed form solution and the solution found by minimizing the loss function iteratively. So use with caution."
      ],
      "metadata": {
        "id": "lu4UzyYtZyS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.linalg.norm(clf.objective_grad(theta1,X,Y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOrZmv-QZ5fT",
        "outputId": "b7a7ad64-dd4a-4b6c-bf05-5ab8c1f57f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.7045541285553925e-06"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.linalg.norm(clf.objective_grad(theta_closed_form,X,Y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vomvXo9MZ91v",
        "outputId": "d62cc29c-71df-444b-b08d-9cbb963b742f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33248616612509513"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.linalg.norm(clf.objective_grad(theta_star,X,Y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqRNFeTZZ_t-",
        "outputId": "ff7e851b-6e28-448a-a74c-9b96e67a8ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3624837946972413"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mj5cD1tiaIeT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}